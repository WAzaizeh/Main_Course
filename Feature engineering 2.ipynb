{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats.mstats import winsorize\n",
    "import scipy.stats\n",
    "import statistics\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'useducation'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "usedu_df = pd.read_sql_query('select * from useducation',con=engine)\n",
    "\n",
    "# no need for an open connection, \n",
    "# as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               bef          aft          aft         \n",
      "PRIMARY_KEY                    0.0          0.0          0.0         \n",
      "STATE                          0.0          0.0          0.0         \n",
      "YEAR                           0.0          0.0          0.0         \n",
      "ENROLL                         17.6         14.1         0.0         \n",
      "TOTAL_REVENUE                  14.2         10.8         0.0         \n",
      "FEDERAL_REVENUE                14.2         10.8         0.0         \n",
      "STATE_REVENUE                  14.2         10.8         0.0         \n",
      "LOCAL_REVENUE                  14.2         10.8         0.0         \n",
      "TOTAL_EXPENDITURE              14.2         10.8         0.0         \n",
      "INSTRUCTION_EXPENDITURE        14.2         10.8         0.0         \n",
      "SUPPORT_SERVICES_EXPENDITURE   14.2         10.8         0.0         \n",
      "OTHER_EXPENDITURE              17.6         14.1         0.0         \n",
      "CAPITAL_OUTLAY_EXPENDITURE     14.2         10.8         0.0         \n",
      "GRADES_PK_G                    11.6         3.28         0.0         \n",
      "GRADES_KG_G                    8.85         0.469        0.0         \n",
      "GRADES_4_G                     8.78         0.469        0.0         \n",
      "GRADES_8_G                     8.78         0.469        0.0         \n",
      "GRADES_12_G                    8.78         0.469        0.0         \n",
      "GRADES_1_8_G                   8.78         0.469        0.0         \n",
      "GRADES_9_12_G                  8.78         0.469        0.0         \n",
      "GRADES_ALL_G                   11.6         3.28         0.0         \n",
      "AVG_MATH_4_SCORE               64.1         14.4         0.0         \n",
      "AVG_MATH_8_SCORE               64.3         14.7         0.0         \n",
      "AVG_READING_4_SCORE            64.3         16.2         0.0         \n",
      "AVG_READING_8_SCORE            66.6         26.5         0.0         \n"
     ]
    }
   ],
   "source": [
    "# using pandas interpolation function to fill missing values\n",
    "fill_cols = usedu_df.columns[3:]\n",
    "states = usedu_df['STATE'].unique()\n",
    "\n",
    "# save empty enteries stats\n",
    "before_inter = (usedu_df.isnull().sum()/usedu_df.shape[0]*100).values\n",
    "\n",
    "for state in states:\n",
    "    usedu_df.loc[usedu_df['STATE'] == state, fill_cols] = usedu_df.loc[usedu_df['STATE'] == state, fill_cols].interpolate()\n",
    "\n",
    "# save empty entries stats after interpolation\n",
    "after_inter = (usedu_df.isnull().sum()/usedu_df.shape[0]*100).values\n",
    "\n",
    "# remaining missing values will be dropped\n",
    "usedu_df.dropna(inplace=True)\n",
    "\n",
    "# save empty entries stats after dropping na's\n",
    "after_drop = (usedu_df.isnull().sum()/usedu_df.shape[0]*100).values\n",
    "\n",
    "# print percent of empty cells before and after imputation\n",
    "impute_ind = (usedu_df.isnull().sum()/usedu_df.shape[0]*100).index\n",
    "print('{0:<30} {1:<12.3} {2:<12.3} {3:<12.3}'.format('', 'before', 'after interpolation', \"after dropping na's\")) \n",
    "for row in zip(impute_ind, before_inter, after_inter, after_drop):\n",
    "    print('{0:<30} {1:<12.3} {2:<12.3} {3:<12.3}'.format(*row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate math & reading weighted means\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
